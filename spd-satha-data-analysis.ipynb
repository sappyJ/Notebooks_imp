{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import *\n\n%matplotlib inline", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## File Writing", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from io import BytesIO  \nimport requests  \nimport json  \nimport pandas as pd\n\ndef put_file(credentials, local_file_name):  \n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage V3.\"\"\"\n    f = open(local_file_name,'r')\n    my_data = f.read()\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n            'password': credentials['password']}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', credentials['container'], '/', local_file_name])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.put(url=url2, headers=headers2, data = my_data )\n    print resp2", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "\n# @hidden_cell\nsatha_credentials = {\n  'auth_url':'https://identity.open.softlayer.com',\n  'project':'object_storage_b3d15058_4aa1_42a1_975f_62c1c8b1699a',\n  'project_id':'1e25eccc8cec40699e74914679c79593',\n  'region':'dallas',\n  'user_id':'f909479c2549457cb3fc79a7445beeff',\n  'domain_id':'0592036926cf47bf87e889ec75d0d38b',\n  'domain_name':'1154437',\n  'username':'member_e28904fb9993787d907536191c825c593c36c601',\n  'password':\"\"\"W-ucS.1Ge_fr.0b(\"\"\",\n  'container':'201710kbankibm',\n  'tenantId':'undefined',\n  'filename':'cat_acronym.csv'\n}\n", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Load data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\nfrom io import StringIO\nimport requests\nimport json\nimport pandas as pd\n\n# @hidden_cell\n# This function accesses a file in your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef get_object_storage_file_with_credentials_b3d150584aa142a1975f62c1c8b1699a(container, filename):\n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage.\"\"\"\n\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_e28904fb9993787d907536191c825c593c36c601','domain': {'id': '0592036926cf47bf87e889ec75d0d38b'},\n            'password': 'W-ucS.1Ge_fr.0b('}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.get(url=url2, headers=headers2)\n    return StringIO(resp2.text)\n\ncc_info = pd.read_csv(get_object_storage_file_with_credentials_b3d150584aa142a1975f62c1c8b1699a('201710kbankibm', 'cc_info.csv'))\ncc_info.head()\n", 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "            card_no card_type      opn_dt  exp_dt  cr_lmt_amt  \\\n0  4410123456000001      visa  1997-10-14    1017       50000   \n1  4410123456000002    master  2010-06-29     620      146000   \n2  4410123456000003      visa  2014-06-18     619       22000   \n3  4410123456000004      visa  2014-11-03    1119     1000000   \n4  4410123456000005      visa  2014-04-10     419       80000   \n\n   prev_cr_lmt_amt  main_zip_cd  cr_line_amt  incm_amt  brth_estb_yr  \n0                0      73120.0        50000     21000        1953.0  \n1                0      43000.0       146000     72000        1965.0  \n2                0      23000.0        22000     20000        1978.0  \n3                0      10200.0      2141000   1800000        1955.0  \n4                0      57160.0        80000     32000        1969.0  ", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>card_no</th>\n      <th>card_type</th>\n      <th>opn_dt</th>\n      <th>exp_dt</th>\n      <th>cr_lmt_amt</th>\n      <th>prev_cr_lmt_amt</th>\n      <th>main_zip_cd</th>\n      <th>cr_line_amt</th>\n      <th>incm_amt</th>\n      <th>brth_estb_yr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4410123456000001</td>\n      <td>visa</td>\n      <td>1997-10-14</td>\n      <td>1017</td>\n      <td>50000</td>\n      <td>0</td>\n      <td>73120.0</td>\n      <td>50000</td>\n      <td>21000</td>\n      <td>1953.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4410123456000002</td>\n      <td>master</td>\n      <td>2010-06-29</td>\n      <td>620</td>\n      <td>146000</td>\n      <td>0</td>\n      <td>43000.0</td>\n      <td>146000</td>\n      <td>72000</td>\n      <td>1965.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4410123456000003</td>\n      <td>visa</td>\n      <td>2014-06-18</td>\n      <td>619</td>\n      <td>22000</td>\n      <td>0</td>\n      <td>23000.0</td>\n      <td>22000</td>\n      <td>20000</td>\n      <td>1978.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4410123456000004</td>\n      <td>visa</td>\n      <td>2014-11-03</td>\n      <td>1119</td>\n      <td>1000000</td>\n      <td>0</td>\n      <td>10200.0</td>\n      <td>2141000</td>\n      <td>1800000</td>\n      <td>1955.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4410123456000005</td>\n      <td>visa</td>\n      <td>2014-04-10</td>\n      <td>419</td>\n      <td>80000</td>\n      <td>0</td>\n      <td>57160.0</td>\n      <td>80000</td>\n      <td>32000</td>\n      <td>1969.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 4
                }
            ], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "\nanswer = pd.read_csv(get_object_storage_file_with_credentials_b3d150584aa142a1975f62c1c8b1699a('201710kbankibm', 'answer.csv'))\nanswer.head()\n", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "   Automobiles and Vehicles-freq  Clothing Stores-freq  \\\n0                              0                     0   \n1                              0                     0   \n2                              0                     0   \n3                              0                     0   \n4                              0                     0   \n\n   Service Providers-freq  Transportation-freq  Utilities-freq  \\\n0                       0                    0               0   \n1                       1                    0               0   \n2                       0                    0               0   \n3                       0                    0               0   \n4                       0                    1               0   \n\n   Automobiles and Vehicles-sum  Clothing Stores-sum  Service Providers-sum  \\\n0                           0.0                  0.0                    0.0   \n1                           0.0                  0.0                 1580.0   \n2                           0.0                  0.0                    0.0   \n3                           0.0                  0.0                    0.0   \n4                           0.0                  0.0                    0.0   \n\n   Transportation-sum  Utilities-sum  \n0                 0.0            0.0  \n1                 0.0            0.0  \n2                 0.0            0.0  \n3                 0.0            0.0  \n4               780.0            0.0  ", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Automobiles and Vehicles-freq</th>\n      <th>Clothing Stores-freq</th>\n      <th>Service Providers-freq</th>\n      <th>Transportation-freq</th>\n      <th>Utilities-freq</th>\n      <th>Automobiles and Vehicles-sum</th>\n      <th>Clothing Stores-sum</th>\n      <th>Service Providers-sum</th>\n      <th>Transportation-sum</th>\n      <th>Utilities-sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1580.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>780.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 5
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "\ncc_log = pd.read_csv(get_object_storage_file_with_credentials_b3d150584aa142a1975f62c1c8b1699a('201710kbankibm', 'cc_log.csv'))\ncc_log.head()\n", 
            "cell_type": "code", 
            "execution_count": 6, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "            card_no                         txn_dt    txn_tm  bill_amt  \\\n0  4410123456098153  2017-03-21T00:00:00.000+07:00  10:22:19      5660   \n1  4410123456018545  2017-03-21T00:00:00.000+07:00  23:30:43       100   \n2  4410123456085556  2017-03-21T00:00:00.000+07:00  07:32:54      1540   \n3  4410123456047294  2017-03-21T00:00:00.000+07:00  05:16:20      1500   \n4  4410123456074332  2017-03-21T00:00:00.000+07:00  13:18:56       680   \n\n  card_acpt_cty  mrch_tp_cd card_type  \n0            TH        4722      visa  \n1            US        5818      visa  \n2            TH        6300      visa  \n3            TH        5541      visa  \n4            TH        5812      visa  ", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>card_no</th>\n      <th>txn_dt</th>\n      <th>txn_tm</th>\n      <th>bill_amt</th>\n      <th>card_acpt_cty</th>\n      <th>mrch_tp_cd</th>\n      <th>card_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4410123456098153</td>\n      <td>2017-03-21T00:00:00.000+07:00</td>\n      <td>10:22:19</td>\n      <td>5660</td>\n      <td>TH</td>\n      <td>4722</td>\n      <td>visa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4410123456018545</td>\n      <td>2017-03-21T00:00:00.000+07:00</td>\n      <td>23:30:43</td>\n      <td>100</td>\n      <td>US</td>\n      <td>5818</td>\n      <td>visa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4410123456085556</td>\n      <td>2017-03-21T00:00:00.000+07:00</td>\n      <td>07:32:54</td>\n      <td>1540</td>\n      <td>TH</td>\n      <td>6300</td>\n      <td>visa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4410123456047294</td>\n      <td>2017-03-21T00:00:00.000+07:00</td>\n      <td>05:16:20</td>\n      <td>1500</td>\n      <td>TH</td>\n      <td>5541</td>\n      <td>visa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4410123456074332</td>\n      <td>2017-03-21T00:00:00.000+07:00</td>\n      <td>13:18:56</td>\n      <td>680</td>\n      <td>TH</td>\n      <td>5812</td>\n      <td>visa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 6
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "\ncc_cat = pd.read_csv(get_object_storage_file_with_credentials_b3d150584aa142a1975f62c1c8b1699a('201710kbankibm', 'Final_categories.csv'))\ncc_cat = cc_cat.rename(str,{'Categories':'Category'})\ncc_cat.head()\n", 
            "cell_type": "code", 
            "execution_count": 7, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "   Category   MCC\n0  Airlines  3000\n1  Airlines  3001\n2  Airlines  3002\n3  Airlines  3003\n4  Airlines  3004", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>MCC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Airlines</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Airlines</td>\n      <td>3001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Airlines</td>\n      <td>3002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Airlines</td>\n      <td>3003</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Airlines</td>\n      <td>3004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 7
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Change data types", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "cc_log['txn_dt'] = pd.to_datetime(cc_log['txn_dt'])", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Joining data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "cc_log = pd.merge(cc_log, cc_cat, how='left', left_on='mrch_tp_cd', right_on='MCC')", 
            "cell_type": "code", 
            "execution_count": 9, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_log['Category'] = cc_log['Category'].fillna('Others')", 
            "cell_type": "code", 
            "execution_count": 10, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_log = cc_log.drop(['mrch_tp_cd'], axis=1)", 
            "cell_type": "code", 
            "execution_count": 11, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Aggregation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "def oneHotAgg(x):\n    temp = {}\n    for cat in ['Automobiles and Vehicles', 'Clothing Stores', 'Service Providers', 'Transportation', 'Utilities']:\n        temp[cat + '-freq'] = (x.loc[x.Category == cat, 'bill_amt']).count()\n        temp[cat + '-sum'] = (x.loc[x.Category == cat,'bill_amt']).sum()\n    return pd.Series(temp)\n\ndef generate_answer(cc_log, year=2017, month=1):\n    cc_answer_pattern = pd.DataFrame({\n    'card_no': cc_info['card_no'],\n    'Automobiles and Vehicles-freq': np.zeros(cc_info['card_no'].shape[0]),\n    'Clothing Stores-freq': np.zeros(cc_info['card_no'].shape[0]),\n    'Service Providers-freq': np.zeros(cc_info['card_no'].shape[0]),\n    'Transportation-freq': np.zeros(cc_info['card_no'].shape[0]),\n    'Utilities-freq': np.zeros(cc_info['card_no'].shape[0]),\n    'Automobiles and Vehicles-sum': np.zeros(cc_info['card_no'].shape[0]),\n    'Clothing Stores-sum': np.zeros(cc_info['card_no'].shape[0]),\n    'Service Providers-sum': np.zeros(cc_info['card_no'].shape[0]),\n    'Transportation-sum': np.zeros(cc_info['card_no'].shape[0]),\n    'Utilities-sum': np.zeros(cc_info['card_no'].shape[0])})\n    cc_log_ans = cc_log.loc[(cc_log['txn_dt'].apply(lambda x:x.month) == month) & \n                                (cc_log['txn_dt'].apply(lambda x:x.year) == year), :]\n    cc_answer = cc_log_ans.groupby('card_no').apply(oneHotAgg).reset_index()\n    \n    tmp = pd.merge(cc_answer_pattern, cc_answer, how='left', on='card_no').fillna(0)\n    \n    for a in [x+y for x in ['Automobiles and Vehicles', 'Clothing Stores', 'Service Providers', 'Transportation', 'Utilities']\n            for y in ['-freq', '-sum']]:\n        tmp[a] = tmp[a + '_x'] + tmp[a + '_y']\n        tmp = tmp.drop([a + '_x', a + '_y'], axis=1)\n\n    return tmp\n", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_answer_201701 = generate_answer(cc_log, year=2017, month=1)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_answer_201601 = generate_answer(cc_log, year=2016, month=1)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Naive Evaluation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "pd.DataFrame(columns=['name'] + [x+y for x in ['Automobiles and Vehicles', 'Clothing Stores', 'Service Providers', 'Transportation', 'Utilities']\n            for y in ['-freq', '-sum']])", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "scores = pd.DataFrame(columns=[x+y for x in ['Automobiles and Vehicles', 'Clothing Stores', 'Service Providers', 'Transportation', 'Utilities']\n            for y in ['-freq', '-sum']])\n\nscoring_data = {\n    '201601_MAE':{\n        'pred': cc_answer_201601,\n        'ans': cc_answer_201701,\n        'fn': mean_absolute_error\n    },\n    '201601_MSE':{\n        'pred': cc_answer_201601,\n        'ans': cc_answer_201701,\n        'fn': mean_squared_error\n    },\n    '201612_MAE':{\n        'pred': cc_answer_201612,\n        'ans': cc_answer_201701,\n        'fn': mean_absolute_error\n    },\n    '201612_MSE':{\n        'pred': cc_answer_201612,\n        'ans': cc_answer_201701,\n        'fn': mean_squared_error\n    }\n}\n\nfor name, data in scoring_data.iteritems():\n    new_data = dict()\n#     new_data['name'] = [name]\n    for a in [x+y for x in ['Automobiles and Vehicles', 'Clothing Stores', 'Service Providers', 'Transportation', 'Utilities']\n                for y in ['-freq', '-sum']]:\n        new_data[a] = [data['fn'](data['pred'][a], data['ans'][a])]\n    scores = scores.append(pd.DataFrame(new_data, index=[name]))\n#     print new_data\n\nscores.head()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Jan 2016 Only", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "cc_log_201601 = cc_log.loc[(cc_log['txn_dt'].apply(lambda x:x.month) == 1) & \n                                (cc_log['txn_dt'].apply(lambda x:x.year) == 2016), :]\n\npd.pivot_table(cc_log_201601, values='bill_amt', index='card_no', columns='Category', \n               aggfunc='sum', fill_value=0).reset_index()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Preprocess data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "cc_answer = cc_answer_201612.copy()\n\ncategories = ['Automobiles and Vehicles', 'Clothing Stores', \n              'Service Providers', 'Transportation', 'Utilities']\n\nfor cat in categories:\n    cc_answer[cat + '_has_spending'] = (cc_answer[cat + '-freq'] > 0).astype(np.int32)\n\nfor col in cc_answer.iloc[:, 1:].columns:\n    cc_answer[col] = cc_answer[col].astype(np.float32)\n    \ncc_answer.head()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "cc_info_agg = cc_info.copy()\n\ncc_info_agg['opn_yr'] = pd.to_datetime(cc_info_agg['opn_dt']).apply(lambda x: x.year)\ncc_info_agg['exp_yr'] = cc_info_agg['exp_dt'].apply(lambda x:2000 + (x % 100))\ncc_info_agg['card_age'] = cc_info_agg['exp_yr'] - cc_info_agg['opn_yr']\ncc_info_agg['age'] = 2017 - cc_info_agg['brth_estb_yr']\n\ncc_info_agg = cc_info_agg.fillna(0)\n\ncc_info_agg = cc_info_agg.drop(['main_zip_cd', 'brth_estb_yr', 'exp_dt', 'opn_dt', 'card_type'], axis=1)\n\nfor col in cc_info_agg.iloc[:, 2:].columns:\n    cc_info_agg[col] = cc_info_agg[col].astype(np.float32)\n\ncc_info_agg.head()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_cat['Category'].unique()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_log_agg_201611 = generate_answer(cc_log, year=2016, month=11)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "last_month = 11\ncc_log_agg_last_month = cc_log.loc[(cc_log['txn_dt'].apply(lambda x: x.month) == last_month) & \n                               (cc_log['txn_dt'].apply(lambda x: x.year) < 2017), :].copy()\ncc_log_agg_3_month = cc_log.loc[(cc_log['txn_dt'].apply(lambda x: x.month) > last_month - 3) & \n                                (cc_log['txn_dt'].apply(lambda x: x.month) <= last_month) &\n                               (cc_log['txn_dt'].apply(lambda x: x.year) < 2017), :].copy()\ncc_log_agg_6_month = cc_log.loc[(cc_log['txn_dt'].apply(lambda x: x.month) > last_month - 6) & \n                                (cc_log['txn_dt'].apply(lambda x: x.month) <= last_month) &\n                               (cc_log['txn_dt'].apply(lambda x: x.year) < 2017), :].copy()\ncc_log_agg_whole_year = cc_log.loc[(cc_log['txn_dt'].apply(lambda x: x.month) <= last_month) &\n                               (cc_log['txn_dt'].apply(lambda x: x.year) < 2017), :].copy()\n", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "opts = ['mean', 'min', 'max', 'count']\n\ngrouped = cc_log_agg_last_month.groupby(['card_no', 'Category']).agg({'bill_amt': opts}).unstack(fill_value=0)\ncc_log_agg_1m = pd.concat([grouped['bill_amt'][opt].reset_index()\\\n                              .rename(columns={x: x + '_1m_' + opt for x in grouped['bill_amt'][opt].columns}) for opt in opts], axis=1)\n# cc_log_agg_1m = cc_log_agg_1m.fillna(0)\n\ngrouped = cc_log_agg_3_month.groupby(['card_no', 'Category']).agg({'bill_amt': opts}).unstack(fill_value=0)\ncc_log_agg_3m = pd.concat([grouped['bill_amt'][opt].reset_index()\\\n                              .rename(columns={x: x + '_3m_' + opt for x in grouped['bill_amt'][opt].columns}) for opt in opts], axis=1)\n# cc_log_agg_3m = cc_log_agg_3m.fillna(0)\n\ngrouped = cc_log_agg_6_month.groupby(['card_no', 'Category']).agg({'bill_amt': opts}).unstack(fill_value=0)\ncc_log_agg_6m = pd.concat([grouped['bill_amt'][opt].reset_index()\\\n                              .rename(columns={x: x + '_6m_' + opt for x in grouped['bill_amt'][opt].columns}) for opt in opts], axis=1)\n# cc_log_agg_6m = cc_log_agg_6m.fillna(0)\n\ngrouped = cc_log_agg_whole_year.groupby(['card_no', 'Category']).agg({'bill_amt': opts}).unstack(fill_value=0)\ncc_log_agg_1y = pd.concat([grouped['bill_amt'][opt].reset_index()\\\n                              .rename(columns={x: x + '_1y_' + opt for x in grouped['bill_amt'][opt].columns}) for opt in opts], axis=1)\n# cc_log_agg_1y = cc_log_agg_1y.fillna(0)\n\n\n", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_log_agg_list = [cc_log_agg_1m, cc_log_agg_3m, cc_log_agg_6m, cc_log_agg_1y]\n\ncc_agg_all = cc_info_agg.copy()\n\nfor cc_log_agg in cc_log_agg_list:\n    cc_agg_all = pd.merge(cc_agg_all, cc_log_agg.loc[: , ~cc_log_agg.columns.duplicated()], how='left', on='card_no')\ncc_agg_all = cc_agg_all.fillna(0)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_agg_all.to_csv('satha_cc_agg_features.csv', index=False)\nput_file(satha_credentials, 'satha_cc_agg_features.csv')", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "cc_log_jannov_agg = cc_log_agg_last_month\n\ngrouped = cc_log_jannov_agg.groupby(['card_no', 'Category']).agg({'bill_amt': opts}).unstack(fill_value=0)\ncc_log_jannov_agg = pd.concat([grouped['bill_amt'][opt].reset_index()\\\n                              .rename(columns={x: x + '_1m_' + opt for x in grouped['bill_amt'][opt].columns}) for opt in opts], axis=1)\ncc_log_jannov_agg = cc_log_jannov_agg.fillna(0)\n\ncc_log_jannov_input = pd.merge(cc_info_agg, \n                               cc_log_jannov_agg.loc[:, ~cc_log_jannov_agg.columns.duplicated()], \n                               how='left', \n                               on='card_no').fillna(0)\n\ncc_log_jannov_input.head()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "cc_input = pd.merge(cc_log_agg_201611, cc_info_agg, how='inner', on='card_no')\n# cc_input = cc_input.drop(['card_type'], axis=1)\ncc_input.head()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Model Building", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics.regression import mean_absolute_error, mean_squared_error\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.lda import LDA", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "prediction_list = [] # a list of (name, model, x, y)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Hopefully-More-Clever Model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "x_train, x_test, y_train, y_test = train_test_split(cc_log_jannov_input.iloc[:, 2:], \n                                                    cc_answer.iloc[:, 1:11], \n                                                    test_size=0.5, \n                                                    random_state=42)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "hmc_model = MultiOutputRegressor(RandomForestRegressor()).fit(x_train, y_train)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "print 'Training MAE: ', mean_absolute_error(y_train, hmc_model.predict(x_train))\nprint 'Training MSE: ', mean_squared_error(y_train, hmc_model.predict(x_train))\nprint 'Testing MAE: ', mean_absolute_error(y_test, hmc_model.predict(x_test))\nprint 'Testing MSE: ', mean_squared_error(y_test, hmc_model.predict(x_test))", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "prediction_list.append(('HMC', hmc_model, cc_log_jannov_input.iloc[:, 2:], cc_answer.iloc[:, 1:11]))", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "hmc_result = hmc_model.predict(cc_log_jannov_input.iloc[:, 2:])\n#hmc_result.to_csv('satha-hmc-result.csv', index=False)\n#put_file(satha_credentials, 'satha-hmc-result.csv')", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "hmc_result.shape", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "hmc_result.head()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }
}