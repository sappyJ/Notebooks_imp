{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "###### Join Mention.csv and Mention_brg.csv first. Then merge with doc_fact.csv. \n###### Hot encode Entities and then group by documentID with max of encoded entities\n\n###### List of entities\n\nReason_Natural_call\n\nReason_Delivery\n\nReason_Parking_Full\n\nReason_Moving\n\nReason_Sickness\n\nAccompying_Wife\n\nAccompanying_Mother\n\nAccompanying_Child\n\nAccompanying_Others\n\nCompassion_Taxi_Driver\n\nCompassion_Firsttime_offenders\n\nCompassion_Financial\n\nCompassion_Future_assurance\n\nCompassion_Noobstruction\n\nOffender_Repeat\n\nOffender_NoRepeat", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#import required packages\nimport pandas as pd\nimport numpy as np\n!pip list", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\u001b[31mDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\u001b[0m\r\nalabaster (0.7.10)\r\nanaconda-client (1.6.5)\r\nanaconda-project (0.8.0)\r\nasn1crypto (0.22.0)\r\nastroid (1.5.3)\r\nastropy (2.0.2)\r\nastunparse (1.5.0)\r\nBabel (2.5.0)\r\nbackports.shutil-get-terminal-size (1.0.0)\r\nbackports.weakref (1.0rc1)\r\nbeautifulsoup4 (4.6.0)\r\nbiopython (1.69)\r\nbitarray (0.8.1)\r\nbkcharts (0.2)\r\nblaze (0.11.3)\r\nbleach (2.0.0)\r\nbokeh (0.12.10)\r\nboto (2.48.0)\r\nboto3 (1.4.7)\r\nbotocore (1.7.20)\r\nBottleneck (1.2.1)\r\nbrunel (2.3)\r\ncertifi (2018.8.24)\r\ncffi (1.10.0)\r\nchardet (3.0.4)\r\nclick (6.7)\r\ncloudpickle (0.4.0)\r\nclyent (1.2.2)\r\ncolorama (0.3.9)\r\ncolour (0.1.5)\r\ncontextlib2 (0.5.5)\r\ncryptography (2.2.2)\r\ncycler (0.10.0)\r\nCython (0.26.1)\r\ncytoolz (0.8.2)\r\ndask (0.15.4)\r\ndatashape (0.5.4)\r\ndebtcollector (1.17.0)\r\ndecorator (4.1.2)\r\ndill (0.2.7.1)\r\ndistributed (1.19.1)\r\ndocutils (0.14)\r\nentrypoints (0.2.3)\r\nenum34 (1.1.6)\r\net-xmlfile (1.0.1)\r\nfastcache (1.0.2)\r\nfilelock (2.0.12)\r\nFlask (0.12.2)\r\nFlask-Cors (3.0.3)\r\nfuture (0.16.0)\r\ngeojson (1.3.5)\r\ngeopy (1.11.0)\r\ngevent (1.2.2)\r\nglob2 (0.5)\r\ngmpy2 (2.0.8)\r\ngreenlet (0.4.12)\r\nh5py (2.7.0)\r\nheapdict (1.0.0)\r\nhtml5lib (0.999999999)\r\nibm-bias-detection (1.0.8)\r\nibm-cos-sdk (2.0.1)\r\nibm-cos-sdk-core (2.0.1)\r\nibm-cos-sdk-s3transfer (2.0.1)\r\nibm-db (2.0.7)\r\nibm-db-sa (0.3.3)\r\nibmdbpy (0.1.5)\r\nidna (2.6)\r\nimageio (2.2.0)\r\nimagesize (0.7.1)\r\nipykernel (4.8.2)\r\nipython (6.1.0)\r\nipython-genutils (0.2.0)\r\nipywidgets (7.1.1)\r\niso8601 (0.1.12)\r\nisort (4.2.15)\r\nitsdangerous (0.24)\r\nJayDeBeApi (0.2.0)\r\njdcal (1.3)\r\njedi (0.10.2)\r\nJinja2 (2.9.6)\r\njmespath (0.9.3)\r\nJPype1 (0.6.2)\r\nJPype1-py3 (0.5.5.2)\r\njsonschema (2.6.0)\r\njupyter-client (5.1.0)\r\njupyter-core (4.3.0)\r\njupyter-pip (0.3.1)\r\nKeras (2.1.4)\r\nkeystoneauth1 (3.2.0)\r\nLasagne (0.2.dev1)\r\nlazy (1.3)\r\nlazy-object-proxy (1.3.1)\r\nllvmlite (0.20.0)\r\nlocket (0.2.0)\r\nlomond (0.1.13)\r\nlxml (4.1.0)\r\nMako (1.0.7)\r\nMarkdown (2.6.9)\r\nMarkupSafe (1.0)\r\nmatplotlib (2.1.0)\r\nmaven-artifact (0.2.0)\r\nmccabe (0.6.1)\r\nmistune (0.8.1)\r\nmonotonic (1.3)\r\nmpld3 (0.3)\r\nmpmath (0.19)\r\nmsgpack-python (0.4.8)\r\nmultipledispatch (0.4.9)\r\nnbconvert (5.3.1)\r\nnbformat (4.4.0)\r\nnetaddr (0.7.19)\r\nnetifaces (0.10.6)\r\nnetworkx (2.0)\r\nnltk (3.2.4)\r\nnose (1.3.7)\r\nnotebook (5.2.1)\r\nnumba (0.35.0+10.g143f70e90)\r\nnumexpr (2.6.2)\r\nnumpy (1.13.3)\r\nnumpydoc (0.7.0)\r\nodo (0.5.1)\r\nolefile (0.44)\r\nopenpyxl (2.4.8)\r\noslo.config (4.12.0)\r\noslo.i18n (3.17.0)\r\noslo.serialization (2.20.0)\r\noslo.utils (3.29.0)\r\npackaging (16.8)\r\npandas (0.21.0)\r\npandocfilters (1.4.2)\r\npartd (0.3.8)\r\npath.py (10.3.1)\r\npathlib2 (2.3.0)\r\npatsy (0.4.1)\r\npbr (3.1.1)\r\npep8 (1.7.0)\r\npexpect (4.2.1)\r\npickleshare (0.7.4)\r\nPillow (4.2.1)\r\npip (9.0.1)\r\npixiedust (1.1.11)\r\npkginfo (1.4.1)\r\nplotly (2.0.14)\r\nply (3.10)\r\npositional (1.2.1)\r\nproject-lib (1.1.1)\r\nprompt-toolkit (1.0.15)\r\nprotobuf (3.4.1)\r\npsutil (5.4.0)\r\npsycopg2 (2.7.4)\r\nptyprocess (0.5.2)\r\npy (1.4.34)\r\npycodestyle (2.3.1)\r\npycosat (0.6.3)\r\npycparser (2.18)\r\npycrypto (2.6.1)\r\npycurl (7.43.0)\r\npyflakes (1.6.0)\r\nPygments (2.2.0)\r\npygpu (0.6.9)\r\npylint (1.7.4)\r\npyodbc (4.0.17)\r\npyOpenSSL (18.0.0)\r\npyparsing (2.2.0)\r\npypyodbc (1.3.4)\r\nPySocks (1.6.7)\r\npytest (3.2.1)\r\npython-dateutil (2.6.1)\r\npython-keystoneclient (3.13.0)\r\npython-swiftclient (3.4.0)\r\npytz (2018.3)\r\nPyWavelets (0.5.2)\r\nPyYAML (3.12)\r\npyzmq (17.0.0)\r\nQtAwesome (0.4.4)\r\nQtPy (1.3.1)\r\nrequests (2.18.4)\r\nrfc3986 (1.1.0)\r\nrope (0.10.5)\r\nruamel-yaml (0.11.14)\r\ns3transfer (0.1.10)\r\nscikit-image (0.13.0)\r\nscikit-learn (0.19.1)\r\nscipy (1.0.0)\r\nseaborn (0.8)\r\nsetuptools (36.5.0.post20170921)\r\nsimplegeneric (0.8.1)\r\nsimplejson (3.11.1)\r\nsingledispatch (3.4.0.3)\r\nsix (1.11.0)\r\nsnowballstemmer (1.2.1)\r\nsortedcollections (0.5.3)\r\nsortedcontainers (1.5.7)\r\nSphinx (1.6.3)\r\nsphinxcontrib-websupport (1.0.1)\r\nSQLAlchemy (1.1.13)\r\nstatsmodels (0.8.0)\r\nstevedore (1.26.0)\r\nstreamsx (1.9.6)\r\nsympy (1.1.1)\r\ntables (3.4.2)\r\ntabulate (0.8.2)\r\ntblib (1.3.2)\r\ntensorflow (1.3.0)\r\nterminado (0.6)\r\ntestpath (0.3.1)\r\nTheano (0.9.0)\r\ntoolz (0.8.2)\r\ntornado (4.5.2)\r\ntqdm (4.19.5)\r\ntraitlets (4.3.2)\r\ntyping (3.6.2)\r\nunicodecsv (0.14.1)\r\nurllib3 (1.22)\r\nwatson-machine-learning-client (1.0.318)\r\nwcwidth (0.1.7)\r\nwebencodings (0.5.1)\r\nWerkzeug (0.12.2)\r\nwheel (0.29.0)\r\nwidgetsnbextension (3.1.0)\r\nwrapt (1.10.11)\r\nxgboost (0.6a2)\r\nxlrd (1.1.0)\r\nXlsxWriter (1.0.2)\r\nxlwt (1.3.0)\r\nzict (0.1.3)\r\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "import sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_8760db995d144d1cab8bb99f8e30e4d7 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='Rx3KcqqyVM0CvH2mcoC-oNhWl4AIgJNnLG4yj6qWbLXG',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about your possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1 = client_8760db995d144d1cab8bb99f8e30e4d7.get_object(Bucket='hdbc3bf4c3bf3454028bc34d6d765ab9a09', Key='mention.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n\nmention = pd.read_csv(streaming_body_1,header=None)\nmention.head()\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>enquiry</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>enquiry</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>software_services</td>\n      <td>outlook</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>enquiry</td>\n      <td>AUP</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   0                  1        2\n0  1            enquiry     spam\n1  1            enquiry     spam\n2  2  software_services  outlook\n3  3            enquiry      AUP"
                    }, 
                    "execution_count": 3, 
                    "metadata": {}
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "#Name columns and drop any duplicates\nmention_2 = pd.DataFrame(mention.values,columns=['facetID','facet','value'])\n\n#print df2\nmention_3= mention_2.drop_duplicates()\nprint (mention_3)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "  facetID              facet    value\n0       1            enquiry     spam\n2       2  software_services  outlook\n3       3            enquiry      AUP\n"
                }
            ], 
            "execution_count": 4
        }, 
        {
            "source": "import sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_8760db995d144d1cab8bb99f8e30e4d7 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='Rx3KcqqyVM0CvH2mcoC-oNhWl4AIgJNnLG4yj6qWbLXG',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about your possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1 = client_8760db995d144d1cab8bb99f8e30e4d7.get_object(Bucket='hdbc3bf4c3bf3454028bc34d6d765ab9a09', Key='mention_brg.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n\nmention_brg = pd.read_csv(streaming_body_1,header=None)\nmention_brg.head()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   0  1\n0  3  1\n1  5  2\n2  5  3\n3  4  1"
                    }, 
                    "execution_count": 5, 
                    "metadata": {}
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "#Name columns \nmention_brg_1 = pd.DataFrame(mention_brg.values,columns=['ID','facetID'])\nprint (mention_brg_1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "   ID  facetID\n0   3        1\n1   5        2\n2   5        3\n3   4        1\n"
                }
            ], 
            "execution_count": 6
        }, 
        {
            "source": "#Join by Right outer join files mention.csv and mention_brg.csv using facetID as the key\nfinal=pd.merge(mention_3, mention_brg_1, on='facetID', how='right')\nprint (final)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "  facetID              facet    value  ID\n0       1            enquiry     spam   3\n1       1            enquiry     spam   4\n2       2  software_services  outlook   5\n3       3            enquiry      AUP   5\n"
                }
            ], 
            "execution_count": 7
        }, 
        {
            "source": "import sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_8760db995d144d1cab8bb99f8e30e4d7 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='Rx3KcqqyVM0CvH2mcoC-oNhWl4AIgJNnLG4yj6qWbLXG',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about your possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1 = client_8760db995d144d1cab8bb99f8e30e4d7.get_object(Bucket='hdbc3bf4c3bf3454028bc34d6d765ab9a09', Key='doc_fact.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n\ndoc_fact = pd.read_csv(streaming_body_1)\ndoc_fact.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>URI</th>\n      <th>DATE</th>\n      <th>DATE_FACET_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>file:///home/esadmin/HDB/data/INC000000702635.txt</td>\n      <td>1479050005000</td>\n      <td>20161113</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>file:///home/esadmin/HDB/data/INC000000701995.txt</td>\n      <td>1479050004000</td>\n      <td>20161113</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>file:///home/esadmin/HDB/data/INC000000701619.txt</td>\n      <td>1479050004000</td>\n      <td>20161113</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   ID                                                URI           DATE  \\\n0   3  file:///home/esadmin/HDB/data/INC000000702635.txt  1479050005000   \n1   4  file:///home/esadmin/HDB/data/INC000000701995.txt  1479050004000   \n2   5  file:///home/esadmin/HDB/data/INC000000701619.txt  1479050004000   \n\n   DATE_FACET_ID  \n0       20161113  \n1       20161113  \n2       20161113  "
                    }, 
                    "execution_count": 8, 
                    "metadata": {}
                }
            ], 
            "execution_count": 8
        }, 
        {
            "source": "# Join by left outer join files doc_face.csv and merged mention using ID as the key\nfinal1=pd.merge(final, doc_fact, on='ID', how='left')\nprint (final1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "  facetID              facet    value  ID  \\\n0       1            enquiry     spam   3   \n1       1            enquiry     spam   4   \n2       2  software_services  outlook   5   \n3       3            enquiry      AUP   5   \n\n                                                 URI           DATE  \\\n0  file:///home/esadmin/HDB/data/INC000000702635.txt  1479050005000   \n1  file:///home/esadmin/HDB/data/INC000000701995.txt  1479050004000   \n2  file:///home/esadmin/HDB/data/INC000000701619.txt  1479050004000   \n3  file:///home/esadmin/HDB/data/INC000000701619.txt  1479050004000   \n\n   DATE_FACET_ID  \n0       20161113  \n1       20161113  \n2       20161113  \n3       20161113  \n"
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "#For Hot encoding multiple columns\n#col=['doc','entity']\n#onehot=pd.get_dummies(df,columns=col)\n\n#Perform one hot encoding of various column facet\nonehot=pd.get_dummies(final1['facet'])\nprint (onehot)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "   enquiry  software_services\n0        1                  0\n1        1                  0\n2        0                  1\n3        1                  0\n"
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "#join one hot encoding back to the original data frame\ndf=final1.drop('value',axis=1)\ndf=df.join(onehot)\nprint (df)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "  facetID              facet  ID  \\\n0       1            enquiry   3   \n1       1            enquiry   4   \n2       2  software_services   5   \n3       3            enquiry   5   \n\n                                                 URI           DATE  \\\n0  file:///home/esadmin/HDB/data/INC000000702635.txt  1479050005000   \n1  file:///home/esadmin/HDB/data/INC000000701995.txt  1479050004000   \n2  file:///home/esadmin/HDB/data/INC000000701619.txt  1479050004000   \n3  file:///home/esadmin/HDB/data/INC000000701619.txt  1479050004000   \n\n   DATE_FACET_ID  enquiry  software_services  \n0       20161113        1                  0  \n1       20161113        1                  0  \n2       20161113        0                  1  \n3       20161113        1                  0  \n"
                }
            ], 
            "execution_count": 11
        }, 
        {
            "source": "#Group by Document ID aggregated by max of encoded entities\ndf= df.groupby(['ID'],as_index=False).agg({'enquiry':max,'software_services':max})\nprint (df)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "   ID  software_services  enquiry\n0   3                  0        1\n1   4                  0        1\n2   5                  1        1\n"
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "#Append columns which are not returned as the entity. Make all such columns as zero.\nnewdft=pd.DataFrame()\nprint (newdft)\nlst=['software_services','enquiry','account','spam']\n#dft=pd.DataFrame(columns=['1'])\n#print dft\n\ncolumns = list(df.columns.values)\nprint (columns)\n\nfor i in lst:\n\tif i in columns:\n\t\tprint ('true')\n\telse:\n\t\tprint (\"false\") \n\t\tprint (i)\n\t\tnewdft=newdft.append({i:''},ignore_index=True)\nprint (newdft)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Empty DataFrame\nColumns: []\nIndex: []\n['ID', 'software_services', 'enquiry']\ntrue\ntrue\nfalse\naccount\nfalse\nspam\n  account spam\n0          NaN\n1     NaN     \n"
                }
            ], 
            "execution_count": 36
        }, 
        {
            "source": "#Append the output columns with all the other columns to make the final dataframe.\n#print (newdft)\ndf_new=pd.concat([df,newdft],axis=1)\n\ndf_new = df_new.replace('', np.nan, regex=True)\ndf_new=df_new.fillna(0)\nprint (df_new)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "  account spam\n0          NaN\n1     NaN     \n   ID  software_services  enquiry  account  spam\n0   3                  0        1      0.0   0.0\n1   4                  0        1      0.0   0.0\n2   5                  1        1      0.0   0.0\n"
                }
            ], 
            "execution_count": 37
        }, 
        {
            "source": "#Call WEX API first. Load the JSON into data object and prepare the data using the below code for scoring.\nent_list=[]\ndic={}\nlt=[]\n\nfor i in data['metadata']['textfacets']:\n\t        \tkeyword=''\n\t        \tdic={}\n\t        \t\n\t        \tif 'mention' in i['path']:\n\t\t\t\t\tprint ('true')\n\t\t\t\t\tkeyword= i['keyword']\n\t\t\t\t\tpath= i['path'][1]\n\t\t\t\t\tprint (path)\n\t\t\t\t\tif path in ent_list:\n\t\t\t\t\t\tprint ('do nothing')\n\t\t\t\t\telse:\n\t\t\t\t\t\tprint (ent_list)\n\t\t\t\t\t\tent_list.append(path)\n\t\t\t\t\t\tdic['ID']=1\n\t\t\t\t\t\tdic[path]=1\n\t\t\t\t\t\tlt.append(dic)\t\nprint (lt)\n\ndf = pd.DataFrame(lt) \nprint (df)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "Missing parentheses in call to 'print' (<ipython-input-14-4bc8d8f4d55d>, line 11)", 
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-4bc8d8f4d55d>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print 'true'\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
                    ], 
                    "ename": "TabError"
                }
            ], 
            "execution_count": 14
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}